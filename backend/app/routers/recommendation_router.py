from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy import and_, func
from pydantic import BaseModel, Field
from typing import List, Literal
from datetime import datetime, date, timedelta
import json

from app.utils.kanana import call_kanana
from starlette.concurrency import run_in_threadpool
import logging


from app.database import get_db
from app.models import Paper, Recommendation, CitationGraph
from app.agents.relation_analysis_agent import RelationAnalysisAgent

router = APIRouter(tags=["recommendations"])

logger = logging.getLogger(__name__)

# ==================== Request/Response ëª¨ë¸ ====================

class PaperItem(BaseModel):
    paper_id: int
    title: str
    authors: List[str]
    recommended_at: str  # YYYY-MM-DD í˜•ì‹
    is_user_requested: bool


class TodayRecommendationsResponse(BaseModel):
    date: str  # YYYY-MM-DD í˜•ì‹ã…Œ
    papers: List[PaperItem]
    total_count: int


class RequestPaperRequest(BaseModel):
    paper_id: int = Field(..., description="ë…¼ë¬¸ ID")
    reason: Literal["common_reference"] = Field(..., description="ì¶”ì²œ ì‚¬ìœ ")


class RequestPaperResponse(BaseModel):
    message: str
    paper_id: int
    title: str
    scheduled_date: str  # YYYY-MM-DD í˜•ì‹


# ==================== Relations API Response ëª¨ë¸ ====================

class GraphNode(BaseModel):
    id: int
    title: str
    type: str  # "recommended" or "common_reference"


class GraphEdge(BaseModel):
    source: int
    target: int
    type: str  # "cites"
    is_influential: bool


class GraphData(BaseModel):
    nodes: List[GraphNode]
    edges: List[GraphEdge]


class CommonReference(BaseModel):
    paper_id: int
    title: str
    cited_by_count: int
    suggestion: str


class Cluster(BaseModel):
    theme: str
    papers: List[int]


class AnalysisData(BaseModel):
    common_references: List[CommonReference]
    clusters: List[Cluster]


class TodayRelationsResponse(BaseModel):
    date: str  # YYYY-MM-DD í˜•ì‹
    graph: GraphData
    analysis: AnalysisData


# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ====================

def parse_json_field(field_value: str) -> List[str]:
    """JSON ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    if not field_value:
        return []
    try:
        parsed = json.loads(field_value)
        if isinstance(parsed, list):
            return parsed
        return []
    except (json.JSONDecodeError, TypeError):
        return []


def format_date(date_obj: datetime) -> str:
    """datetimeì„ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(date_obj, datetime):
        return date_obj.strftime("%Y-%m-%d")
    elif isinstance(date_obj, date):
        return date_obj.strftime("%Y-%m-%d")
    return ""


# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

DEMO_COMMON_REFERENCE_PAPER_ID = 99999999
DEMO_COMMON_REFERENCE_TITLE = "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (RAG)"
# ----------------------------------------------------------------------

@router.get("/{user_id}/recommendations/today", response_model=TodayRecommendationsResponse, status_code=status.HTTP_200_OK)
async def get_today_recommendations(user_id: int, db: Session = Depends(get_db)):
    """
    ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë…¼ë¬¸ ì¡°íšŒ
    """
    # ì˜¤ëŠ˜ ë‚ ì§œ (ì‹œê°„ ì œì™¸)
    today = date.today()
    today_start = datetime.combine(today, datetime.min.time())
    today_end = datetime.combine(today, datetime.max.time())
    
    # ì˜¤ëŠ˜ ë‚ ì§œì˜ ì¶”ì²œ ë…¼ë¬¸ ì¡°íšŒ
    recommendations = db.query(Recommendation).filter(
        and_(
            Recommendation.user_id == user_id,
            Recommendation.recommended_at >= today_start,
            Recommendation.recommended_at <= today_end
        )
    ).order_by(Recommendation.recommended_at.desc()).all()
    
    papers_list = []
    for rec in recommendations:
        paper = rec.paper
        if not paper:
            continue
        
        # authors íŒŒì‹±
        authors = parse_json_field(paper.authors) if paper.authors else []
        
        # recommended_atì„ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        recommended_at_str = format_date(rec.recommended_at)
        if not recommended_at_str:
            continue
        
        papers_list.append(PaperItem(
            paper_id=paper.paper_id,
            title=paper.title,
            authors=authors,
            recommended_at=recommended_at_str,
            is_user_requested=rec.is_user_requested
        ))
    
    return TodayRecommendationsResponse(
        date=today.strftime("%Y-%m-%d"),
        papers=papers_list,
        total_count=len(papers_list)
    )


@router.get("/{user_id}/recommendations/today/relations1", response_model=TodayRelationsResponse, status_code=status.HTTP_200_OK)
async def get_today_recommendations_relations(user_id: int, db: Session = Depends(get_db)):
    """
    ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë…¼ë¬¸ ì¸ìš© ê´€ê³„ ë¶„ì„
    """
    # ì˜¤ëŠ˜ ë‚ ì§œ (ì‹œê°„ ì œì™¸)
    today = date.today()
    today_start = datetime.combine(today, datetime.min.time())
    today_end = datetime.combine(today, datetime.max.time())
    
    # 1. ì˜¤ëŠ˜ ë‚ ì§œì˜ ì¶”ì²œ ë…¼ë¬¸ ì¡°íšŒ (ê¸°ì¡´ ë¡œì§ ìœ ì§€ - DBì—ì„œ ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ 3ê°œë¥¼ ê°€ì ¸ì˜´)
    recommendations = db.query(Recommendation).filter(
        and_(
            Recommendation.user_id == user_id,
            Recommendation.recommended_at >= today_start,
            Recommendation.recommended_at <= today_end,
            Recommendation.is_user_requested == False # <<< ì¶”ê°€ëœ ì¡°ê±´
        )
    ).order_by(Recommendation.recommended_at.desc()).all()
    
    # ë°ëª¨ë¥¼ ìœ„í•´ ìµœì†Œ 3ê°œì˜ ë…¼ë¬¸ì´ í•„ìš”í•˜ë‹¤ê³  ê°€ì • (DBì— 3ê°œ ì´ìƒ ìˆì–´ì•¼ í•¨)
    if len(recommendations) < 3:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ì´ 3ê°œ ë¯¸ë§Œì´ê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ë¥¼ ìœ„í•´ 3ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    # ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ (ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©)
    papers_for_analysis = []
    paper_id_to_paper = {}
    
    for rec in recommendations[:3]: # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        paper = rec.paper
        if not paper:
            continue
        
        # external_idì—ì„œ arxiv_id ì¶”ì¶œ (ë°ëª¨ì—ì„œëŠ” í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        arxiv_id = None
        if paper.external_id:
            if paper.external_id.startswith("arXiv:"):
                arxiv_id = paper.external_id.replace("arXiv:", "")
            else:
                arxiv_id = paper.external_id
        
        # arxiv_idê°€ ì—†ì–´ë„ ì‹œì—°ì„ ìœ„í•´ db_paper_idëŠ” ìˆì–´ì•¼ í•¨
        if not paper.paper_id:
             continue
        
        paper_dict = {
            "arxiv_id": arxiv_id,
            "title": paper.title,
            "db_paper_id": paper.paper_id
        }
        papers_for_analysis.append(paper_dict)
        paper_id_to_paper[paper.paper_id] = paper
        
    if len(papers_for_analysis) < 3:
         raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="DBì—ì„œ ìœ íš¨í•œ ë…¼ë¬¸ IDë¥¼ ê°€ì§„ ì¶”ì²œ ë…¼ë¬¸ 3ê°œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
         )
    
    # 2. ë…¸ë“œ ë° ì—ì§€ ìƒì„± (ë°ëª¨ìš© í•˜ë“œì½”ë”© ì‹œì‘)
    nodes = []
    edges = []
    recommended_paper_ids = []
    
    # 2-1. ì¶”ì²œ ë…¼ë¬¸ ë…¸ë“œ ìƒì„±
    for paper_dict in papers_for_analysis:
        paper_id = paper_dict.get("db_paper_id")
        nodes.append(GraphNode(
            id=paper_id,
            title=paper_dict.get("title", ""),
            type="recommended"
        ))
        recommended_paper_ids.append(paper_id)
        
    # 2-2. í•˜ë“œì½”ë”©ëœ ê³µí†µ ì°¸ê³ ë¬¸í—Œ ë…¸ë“œ ìƒì„±
    # RAG ëŒ€í‘œ ë…¼ë¬¸ ì •ë³´ (DEMO_COMMON_REFERENCE_PAPER_IDëŠ” ì‹œì—°ìš© ì„ì‹œ ID)
    rag_ref_id = DEMO_COMMON_REFERENCE_PAPER_ID 
    rag_ref_title = DEMO_COMMON_REFERENCE_TITLE
    cited_by_count = len(recommended_paper_ids) # 3
    
    nodes.append(GraphNode(
        id=rag_ref_id,
        title=rag_ref_title,
        type="common_reference"
    ))
    
    # 2-3. í•˜ë“œì½”ë”©ëœ ì—ì§€ ìƒì„± (ì¶”ì²œ ë…¼ë¬¸ 3ê°œê°€ RAG ë…¼ë¬¸ì„ ëª¨ë‘ ì¸ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ì„¤ì •)
    for citing_id in recommended_paper_ids:
        # ëª¨ë“  ì¸ìš© ê´€ê³„ë¥¼ is_influential=Trueë¡œ ì„¤ì •í•˜ì—¬ ê°•ì¡°
        edges.append(GraphEdge(
            source=citing_id,
            target=rag_ref_id, # RAG ë…¼ë¬¸ ID
            type="cites",
            is_influential=True
        ))
    
    # 3. AnalysisDataì˜ common_references í•˜ë“œì½”ë”©
    common_references = []
    suggestion = f"ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ {cited_by_count}í¸ì´ ëª¨ë‘ ì´ ë…¼ë¬¸ì„ ì¸ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ì¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
    
    common_references.append(CommonReference(
        paper_id=rag_ref_id,
        title=rag_ref_title,
        cited_by_count=cited_by_count,
        suggestion=suggestion
    ))
    
    # Kanana í˜¸ì¶œ ë° DB CitationGraph ì¡°íšŒ ë¡œì§ì€ ìŠ¤í‚µë¨
    # -> ê³µí†µ ì°¸ê³ ë¬¸í—Œì„ 1ê°œ(RAG ë…¼ë¬¸)ë§Œ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ Kanana ë¡œì§(else)ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ.
    
    # 4. í´ëŸ¬ìŠ¤í„° ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€ ë˜ëŠ” ë°ëª¨ì— ë§ê²Œ ìˆ˜ì •)
    clusters = []
    if len(papers_for_analysis) >= 2:
        # ë°ëª¨ ì‹œì—°ì„ ìœ„í•œ í´ëŸ¬ìŠ¤í„°ë§
        theme = "RAG Model Variants"  # ë°ëª¨ìš© ì£¼ì œ
        cluster_papers = [p.get("db_paper_id") for p in papers_for_analysis[:3] if p.get("db_paper_id")]
        if cluster_papers:
            clusters.append(Cluster(
                theme=theme,
                papers=cluster_papers
            ))
    
    # 5. ìµœì¢… ì‘ë‹µ ë°˜í™˜
    return TodayRelationsResponse(
        date=today.strftime("%Y-%m-%d"),
        graph=GraphData(
            nodes=nodes,
            edges=edges
        ),
        analysis=AnalysisData(
            common_references=common_references, # í•˜ë“œì½”ë”©ëœ RAG ë…¼ë¬¸ 1ê°œë§Œ í¬í•¨
            clusters=clusters
        )
    )


@router.get("/{user_id}/recommendations/today/relations", response_model=TodayRelationsResponse, status_code=status.HTTP_200_OK)
async def get_today_recommendations_relations(user_id: int, db: Session = Depends(get_db)):
    """
    ì˜¤ëŠ˜ì˜ ì¶”ì²œ ë…¼ë¬¸ ì¸ìš© ê´€ê³„ ë¶„ì„
    """
    # ì˜¤ëŠ˜ ë‚ ì§œ (ì‹œê°„ ì œì™¸)
    today = date.today()
    today_start = datetime.combine(today, datetime.min.time())
    today_end = datetime.combine(today, datetime.max.time())
    
    # ì˜¤ëŠ˜ ë‚ ì§œì˜ ì¶”ì²œ ë…¼ë¬¸ ì¡°íšŒ
    recommendations = db.query(Recommendation).filter(
        and_(
            Recommendation.user_id == user_id,
            Recommendation.recommended_at >= today_start,
            Recommendation.recommended_at <= today_end
        )
    ).order_by(Recommendation.recommended_at.desc()).all()
    
    if len(recommendations) == 0:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
        )
    
    # ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ (RelationAnalysisAgentìš© í˜•ì‹)
    papers_for_analysis = []
    paper_id_to_paper = {}
    
    for rec in recommendations:
        paper = rec.paper
        if not paper:
            continue
        
        # external_idì—ì„œ arxiv_id ì¶”ì¶œ
        arxiv_id = None
        if paper.external_id:
            if paper.external_id.startswith("arXiv:"):
                arxiv_id = paper.external_id.replace("arXiv:", "")
            else:
                arxiv_id = paper.external_id
        
        if not arxiv_id:
            continue
        
        paper_dict = {
            "arxiv_id": arxiv_id,
            "title": paper.title,
            "db_paper_id": paper.paper_id
        }
        papers_for_analysis.append(paper_dict)
        paper_id_to_paper[paper.paper_id] = paper
    
    if len(papers_for_analysis) == 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. (arXiv ID í•„ìš”)"
        )
    
    # ë…¸ë“œ ìƒì„± (ì¶”ì²œ ë…¼ë¬¸ + ê³µí†µ ì¸ìš© ë…¼ë¬¸)
    nodes = []
    edges = []
    
    # ì¶”ì²œ ë…¼ë¬¸ ë…¸ë“œ ìƒì„±
    recommended_paper_ids = []
    for paper_dict in papers_for_analysis:
        paper_id = paper_dict.get("db_paper_id")
        if paper_id:
            nodes.append(GraphNode(
                id=paper_id,
                title=paper_dict.get("title", ""),
                type="recommended"
            ))
            recommended_paper_ids.append(paper_id)
    
    # DBì˜ CitationGraphì—ì„œ ê³µí†µ ì¸ìš© ë…¼ë¬¸ ì°¾ê¸°
    common_references = []  # ì—¬ê¸°ì„œ ì´ˆê¸°í™”
    
    if len(recommended_paper_ids) >= 2:
        # ê° ì¶”ì²œ ë…¼ë¬¸ì´ ì¸ìš©í•˜ëŠ” ë…¼ë¬¸ë“¤ ì°¾ê¸°
        citations = db.query(CitationGraph).filter(
            CitationGraph.citing_paper_id.in_(recommended_paper_ids)
        ).all()
        
        # cited_paper_idë³„ë¡œ ì¸ìš©í•œ ë…¼ë¬¸ ìˆ˜ ì§‘ê³„
        cited_paper_counts = {}
        citation_edges = {}  # (citing_id, cited_id) -> is_influential
        
        for citation in citations:
            cited_id = citation.cited_paper_id
            citing_id = citation.citing_paper_id
            
            if cited_id not in cited_paper_counts:
                cited_paper_counts[cited_id] = 0
            cited_paper_counts[cited_id] += 1
            
            # ì—ì§€ ì •ë³´ ì €ì¥
            key = (citing_id, cited_id)
            citation_edges[key] = bool(citation.is_influential)
        
        # ëª¨ë“  ì¶”ì²œ ë…¼ë¬¸ì´ ê³µí†µìœ¼ë¡œ ì¸ìš©í•œ ë…¼ë¬¸ ì°¾ê¸° (ì¸ìš© ìˆ˜ê°€ ì¶”ì²œ ë…¼ë¬¸ ìˆ˜ì™€ ê°™ìœ¼ë©´ ê³µí†µ ì¸ìš©)
        common_reference_papers = []
        for cited_id, count in cited_paper_counts.items():
            if count == len(recommended_paper_ids):  # ëª¨ë“  ì¶”ì²œ ë…¼ë¬¸ì´ ì¸ìš©
                cited_paper = db.query(Paper).filter(Paper.paper_id == cited_id).first()
                if cited_paper:
                    # common_reference ë…¸ë“œ ì¶”ê°€
                    if not any(node.id == cited_paper.paper_id for node in nodes):
                        nodes.append(GraphNode(
                            id=cited_paper.paper_id,
                            title=cited_paper.title,
                            type="common_reference"
                        ))
                    
                    # ì—ì§€ ìƒì„±
                    edge_list = []
                    for citing_id in recommended_paper_ids:
                        key = (citing_id, cited_id)
                        is_influential = citation_edges.get(key, False)
                        edges.append(GraphEdge(
                            source=citing_id,
                            target=cited_id,
                            type="cites",
                            is_influential=is_influential
                        ))
                        edge_list.append({
                            "source": citing_id,
                            "target": cited_id,
                            "is_influential": is_influential
                        })
                    
                    common_reference_papers.append({
                        "paper": cited_paper,
                        "cited_by_count": count,
                        "edges": edge_list
                    })
        
        # ê³µí†µ ì°¸ê³ ë¬¸í—Œ ì •ë³´ ìƒì„±
        if len(common_reference_papers) == 0:
            # ê³µí†µ ì¸ìš© ë…¼ë¬¸ì´ ì—†ëŠ” ê²½ìš° - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìœ ì§€
            pass
        elif len(common_reference_papers) == 1:
            # ê³µí†µ ì¸ìš© ë…¼ë¬¸ì´ 1ê°œì¸ ê²½ìš° - ë°”ë¡œ ì¶”ê°€
            ref_info = common_reference_papers[0]
            paper = ref_info["paper"]
            cited_count = ref_info["cited_by_count"]
            suggestion = f"ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ {cited_count}í¸ì´ ëª¨ë‘ ì´ ë…¼ë¬¸ì„ ì¸ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ì¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
            
            common_references.append(CommonReference(
                paper_id=paper.paper_id,
                title=paper.title,
                cited_by_count=cited_count,
                suggestion=suggestion
            ))
        else:
            # ê³µí†µ ì¸ìš© ë…¼ë¬¸ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš° - Kananaë¡œ í•˜ë‚˜ ì„ íƒ
            try:
                # ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ ì œëª© ë¦¬ìŠ¤íŠ¸
                recommended_titles = [p.get("title", "") for p in papers_for_analysis]
                
                # ê³µí†µ ì¸ìš© ë…¼ë¬¸ ì œëª© ë¦¬ìŠ¤íŠ¸
                common_ref_titles = [ref_info["paper"].title for ref_info in common_reference_papers]
                
                # Kanana í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = f"""ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ 3ê°œì™€ ì´ë“¤ì´ ê³µí†µìœ¼ë¡œ ì¸ìš©í•˜ëŠ” ë…¼ë¬¸ë“¤ì´ ìˆìŠµë‹ˆë‹¤.
ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒìœ¼ë¡œ ì¶”ì²œí•  ë…¼ë¬¸ì„ ê³µí†µ ì¸ìš© ë…¼ë¬¸ ì¤‘ì—ì„œ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš”.

**ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸:**
{chr(10).join(f"{i+1}. {title}" for i, title in enumerate(recommended_titles))}

**ê³µí†µìœ¼ë¡œ ì¸ìš©í•˜ëŠ” ë…¼ë¬¸ë“¤:**
{chr(10).join(f"{i+1}. {title}" for i, title in enumerate(common_ref_titles))}

ìœ„ 3ê°œì˜ ì¶”ì²œ ë…¼ë¬¸ê³¼ ê´€ê³„ê°€ ê°€ì¥ ê¹Šë‹¤ê³  íŒë‹¨ë˜ëŠ” ê³µí†µ ì¸ìš© ë…¼ë¬¸ 1ê°œë¥¼ ì„ íƒí•˜ê³ , ê·¸ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì´ í•´ì£¼ì„¸ìš”:
ì„ íƒëœ ë…¼ë¬¸ ë²ˆí˜¸: [ë²ˆí˜¸]
ì´ìœ : [í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ]"""

                # Kanana í˜¸ì¶œ (ë¹„ë™ê¸°)
                response_text = await run_in_threadpool(call_kanana, prompt)
                
                if not response_text:
                    raise Exception("Kananaì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
                # ì‘ë‹µ íŒŒì‹±
                selected_index = None
                for line in response_text.split('\n'):
                    if 'ì„ íƒëœ ë…¼ë¬¸ ë²ˆí˜¸' in line or 'ì„ íƒ' in line:
                        # ìˆ«ì ì¶”ì¶œ
                        import re
                        numbers = re.findall(r'\d+', line)
                        if numbers:
                            selected_index = int(numbers[0]) - 1  # 0-based index
                            break
                
                # ì„ íƒëœ ë…¼ë¬¸ ì¶”ê°€
                if selected_index is not None and 0 <= selected_index < len(common_reference_papers):
                    ref_info = common_reference_papers[selected_index]
                    paper = ref_info["paper"]
                    cited_count = ref_info["cited_by_count"]
                    suggestion = f"ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ {cited_count}í¸ì´ ëª¨ë‘ ì´ ë…¼ë¬¸ì„ ì¸ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ì¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
                    
                    common_references.append(CommonReference(
                        paper_id=paper.paper_id,
                        title=paper.title,
                        cited_by_count=cited_count,
                        suggestion=suggestion
                    ))
                else:
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ë…¼ë¬¸ ì„ íƒ
                    logger.warning(f"Kanana ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì²« ë²ˆì§¸ ë…¼ë¬¸ ì„ íƒ. ì‘ë‹µ: {response_text}")
                    ref_info = common_reference_papers[0]
                    paper = ref_info["paper"]
                    cited_count = ref_info["cited_by_count"]
                    suggestion = f"ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ {cited_count}í¸ì´ ëª¨ë‘ ì´ ë…¼ë¬¸ì„ ì¸ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ì¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
                    
                    common_references.append(CommonReference(
                        paper_id=paper.paper_id,
                        title=paper.title,
                        cited_by_count=cited_count,
                        suggestion=suggestion
                    ))
                    
            except Exception as e:
                # Kanana í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ë…¼ë¬¸ ì„ íƒ
                logger.error(f"Kananaë¥¼ ì´ìš©í•œ ë…¼ë¬¸ ì„ íƒ ì‹¤íŒ¨: {e}", exc_info=True)
                ref_info = common_reference_papers[0]
                paper = ref_info["paper"]
                cited_count = ref_info["cited_by_count"]
                suggestion = f"ì˜¤ëŠ˜ ì¶”ì²œëœ ë…¼ë¬¸ {cited_count}í¸ì´ ëª¨ë‘ ì´ ë…¼ë¬¸ì„ ì¸ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ì¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?"
                
                common_references.append(CommonReference(
                    paper_id=paper.paper_id,
                    title=paper.title,
                    cited_by_count=cited_count,
                    suggestion=suggestion
                ))
    
    # í´ëŸ¬ìŠ¤í„° ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„: ì œëª© í‚¤ì›Œë“œ ê¸°ë°˜)
    clusters = []
    if len(papers_for_analysis) >= 2:
        # ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„°ë§: ì œëª©ì— ê³µí†µ í‚¤ì›Œë“œê°€ ìˆëŠ” ë…¼ë¬¸ë“¤ì„ ê·¸ë£¹í™”
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ì´ í•„ìš”
        theme = "Transformer-based Retrieval"  # ì˜ˆì‹œ
        cluster_papers = [p.get("db_paper_id") for p in papers_for_analysis[:2] if p.get("db_paper_id")]
        if cluster_papers:
            clusters.append(Cluster(
                theme=theme,
                papers=cluster_papers
            ))
    
    return TodayRelationsResponse(
        date=today.strftime("%Y-%m-%d"),
        graph=GraphData(
            nodes=nodes,
            edges=edges
        ),
        analysis=AnalysisData(
            common_references=common_references,
            clusters=clusters
        )
    )


@router.post("/{user_id}/recommendations/request-paper", response_model=RequestPaperResponse, status_code=status.HTTP_201_CREATED)
async def request_paper(user_id: int, request: RequestPaperRequest, db: Session = Depends(get_db)):
    """
    ê³µí†µ ì°¸ê³ ë¬¸í—Œ ì¶”ì²œ ìˆ˜ë½
    ì¸ìš© ê´€ê³„ ë¶„ì„ì„ í†µí•´ ì œì•ˆëœ ë‹¤ìŒ ì¶”ì²œ ë…¼ë¬¸ì„ ë‚´ì¼ ì¶”ì²œ ëª©ë¡ì— ì¶”ê°€
    """
    # ë…¼ë¬¸ ì¡°íšŒ
    paper = db.query(Paper).filter(Paper.paper_id == request.paper_id).first()
    if not paper:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    # ë‚´ì¼ ë‚ ì§œ ê³„ì‚°
    tomorrow = date.today() + timedelta(days=1)
    tomorrow_datetime = datetime.combine(tomorrow, datetime.min.time())

    # ë‚´ì¼ ë‚ ì§œë¡œ ì´ë¯¸ ì¶”ì²œ ìš”ì²­í•œ ë…¼ë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸
    existing = db.query(Recommendation).filter(
        Recommendation.user_id == user_id,
        Recommendation.paper_id == request.paper_id,
        Recommendation.recommended_at == tomorrow_datetime
    ).first()

    if existing:
        # ì´ë¯¸ ì¶”ì²œëœ ë…¼ë¬¸ì¼ ê²½ìš° DB ë³€ê²½ ì—†ì´ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜
        return RequestPaperResponse(
            message="ì´ë¯¸ ì¶”ì²œë°›ê¸°ë¡œ í•œ ë…¼ë¬¸ì…ë‹ˆë‹¤.",
            paper_id=paper.paper_id,
            title=paper.title,
            scheduled_date=tomorrow.strftime("%Y-%m-%d")
        )

    # ì¤‘ë³µì´ ì•„ë‹ˆë©´ ìƒˆ ì¶”ì²œ ìƒì„±
    new_recommendation = Recommendation(
        user_id=user_id,
        paper_id=request.paper_id,
        recommended_at=tomorrow_datetime,
        is_user_requested=True,
        requested_paper_id=request.paper_id if request.reason == "common_reference" else None
    )
    
    db.add(new_recommendation)
    db.commit()
    db.refresh(new_recommendation)
    
    return RequestPaperResponse(
        message="ë‚´ì¼ ë…¼ë¬¸ ì¶”ì²œ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.",
        paper_id=paper.paper_id,
        title=paper.title,
        scheduled_date=tomorrow.strftime("%Y-%m-%d")
    )

@router.post("/{user_id}/recommendations/request-paper1", response_model=RequestPaperResponse, status_code=status.HTTP_201_CREATED)
async def request_paper(user_id: int, request: RequestPaperRequest, db: Session = Depends(get_db)):
    """
    ê³µí†µ ì°¸ê³ ë¬¸í—Œ ì¶”ì²œ ìˆ˜ë½
    ì¸ìš© ê´€ê³„ ë¶„ì„ì„ í†µí•´ ì œì•ˆëœ ë‹¤ìŒ ì¶”ì²œ ë…¼ë¬¸ì„ ë‚´ì¼ ì¶”ì²œ ëª©ë¡ì— ì¶”ê°€
    """
    # --- âš ï¸ ë°ëª¨ ëª¨ë“œë¥¼ ìœ„í•´ ì•„ë˜ ë¡œì§ì€ ë¬´ì‹œë©ë‹ˆë‹¤ âš ï¸ ---
    # ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì´ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

    # ë…¼ë¬¸ ì¡°íšŒ (ë…¼ë¬¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ë§Œ í™•ì¸. Paper ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.)
    
    
    # ë‚´ì¼ ë‚ ì§œ ê³„ì‚°
    tomorrow = date.today() + timedelta(days=1)

    # ğŸ’¡ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…(existing í™•ì¸, new_recommendation ìƒì„± ë° commit)ì„ ëª¨ë‘ ê±´ë„ˆë›°ê³ 
    #    ë¬´ì¡°ê±´ ì„±ê³µ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    return RequestPaperResponse(
        message="ë‚´ì¼ ë…¼ë¬¸ ì¶”ì²œ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.",
        paper_id=1000,
        title="title",
        scheduled_date=tomorrow.strftime("%Y-%m-%d")
    )

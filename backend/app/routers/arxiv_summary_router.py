"""
arXiv ID ê¸°ë°˜ ë…¼ë¬¸ ì¶”ê°€ ë¼ìš°í„°
backend/app/routers/arxiv_summary_router.py
"""

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel, Field
from typing import Literal
import json
import arxiv

from app.database import get_db
from app.models import Paper, PaperMetadata, User, Recommendation
from app.agents.paper_description_agent import PaperDescriptionAgent
from datetime import datetime


router = APIRouter(
    prefix="/papers",
    tags=["papers"]
)


# Request/Response ëª¨ë¸
class ArxivAddRequest(BaseModel):
    arxiv_id: str = Field(..., description="arXiv ë…¼ë¬¸ ID (ì˜ˆ: 2005.11401)")
    user_id: int = Field(..., description="ì‚¬ìš©ì ID")


class ArxivAddResponse(BaseModel):
    message: str


def fetch_arxiv_paper(arxiv_id: str) -> dict:
    """arXiv APIë¡œ ë…¼ë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        
        # arxiv_id ì •ê·œí™” (ì ‘ë‘ì‚¬, ë²„ì „ ë²ˆí˜¸ ì œê±°)
        clean_id = arxiv_id.replace("arXiv:", "").replace("arxiv:", "").split("v")[0].strip()
        
        # arXiv API í˜¸ì¶œ
        client = arxiv.Client()
        search = arxiv.Search(id_list=[clean_id])
        paper = next(client.results(search))
        
        return {
            "arxiv_id": clean_id,
            "title": paper.title,
            "authors": [author.name for author in paper.authors],
            "abstract": paper.summary,
            "published_date": paper.published.strftime("%Y-%m-%d") if paper.published else None,
            "pdf_url": paper.pdf_url,
            "categories": paper.categories
        }
    except StopIteration:
        raise HTTPException(status_code=404, detail=f"arXiv ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {arxiv_id}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"arXiv API ì˜¤ë¥˜: {str(e)}")


def get_semantic_scholar_metadata(arxiv_id: str) -> dict:
    """Semantic Scholar APIë¡œ ì¸ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    import requests
    
    try:
        url = f"https://api.semanticscholar.org/graph/v1/paper/arXiv:{arxiv_id}"
        params = {
            "fields": "citationCount,citationVelocity,influentialCitationCount,year,venue"
        }
        response = requests.get(url, params=params, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            return {
                "citation_count": data.get("citationCount", 0),
                "citation_velocity": data.get("citationVelocity", 0),
                "influential_citation_count": data.get("influentialCitationCount", 0),
                "year": data.get("year"),
                "venue": data.get("venue", "")
            }
    except Exception as e:
        print(f"Semantic Scholar API ì˜¤ë¥˜: {e}")
    
    # ê¸°ë³¸ê°’ ë°˜í™˜
    return {
        "citation_count": 0,
        "citation_velocity": 0,
        "influential_citation_count": 0,
        "year": None,
        "venue": ""
    }


def save_paper_to_db(paper_data: dict, db: Session) -> int:
    """ë…¼ë¬¸ì„ DBì— ì €ì¥í•˜ê³  paper_id ë°˜í™˜"""
    arxiv_id = paper_data.get("arxiv_id")
    external_id = f"arXiv:{arxiv_id}"
    
    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë…¼ë¬¸ì¸ì§€ í™•ì¸
    existing = db.query(Paper).filter(Paper.external_id == external_id).first()
    
    if existing:
        paper_id = existing.paper_id
        # ê¸°ì¡´ ë…¼ë¬¸ ì—…ë°ì´íŠ¸
        existing.title = paper_data.get("title", existing.title)
        existing.authors = json.dumps(paper_data.get("authors", []))
        existing.published_date = paper_data.get("published_date")
        existing.source = "arXiv"
        existing.pdf_url = paper_data.get("pdf_url")
        existing.abstract = paper_data.get("abstract")
    else:
        # ìƒˆ ë…¼ë¬¸ ìƒì„±
        new_paper = Paper(
            title=paper_data.get("title", ""),
            authors=json.dumps(paper_data.get("authors", [])),
            published_date=paper_data.get("published_date"),
            source="arXiv",
            external_id=external_id,
            pdf_url=paper_data.get("pdf_url"),
            abstract=paper_data.get("abstract", "")
        )
        db.add(new_paper)
        db.flush()
        paper_id = new_paper.paper_id
    
    # PaperMetadata ì €ì¥/ì—…ë°ì´íŠ¸
    metadata = db.query(PaperMetadata).filter(
        PaperMetadata.paper_id == paper_id
    ).first()
    
    if not metadata:
        metadata = PaperMetadata(paper_id=paper_id)
        db.add(metadata)
    
    # Semantic Scholar ë©”íŠ¸ë¦­ ì €ì¥
    metadata.citation_count = paper_data.get("citation_count", 0)
    metadata.citation_velocity = paper_data.get("citation_velocity", 0)
    metadata.influential_citation_count = paper_data.get("influential_citation_count", 0)
    
    # í‚¤ì›Œë“œ ì €ì¥
    if paper_data.get("categories"):
        metadata.keywords = json.dumps(paper_data["categories"])
    
    db.commit()
    return paper_id


@router.post("/add", response_model=ArxivAddResponse)
async def add_arxiv_paper(
    request: ArxivAddRequest,
    db: Session = Depends(get_db)
):
    """
    arXiv IDë¡œ ë…¼ë¬¸ì„ DBì— ì¶”ê°€
    
    - DBì— ì´ë¯¸ ìˆìœ¼ë©´: "ì´ë¯¸ í•™ìŠµí•œ ë…¼ë¬¸ì…ë‹ˆë‹¤"
    - DBì— ì—†ìœ¼ë©´: arXivì—ì„œ ê°€ì ¸ì™€ì„œ ì €ì¥ í›„ "ë…¼ë¬¸ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. 'ì§€ê¸ˆê¹Œì§€ ê³µë¶€í•œ ë…¼ë¬¸' í™”ë©´ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”!"
    
    Args:
        - arxiv_id: arXiv ë…¼ë¬¸ ID (ì˜ˆ: 2005.11401, arXiv:2005.11401 ë‘˜ ë‹¤ ê°€ëŠ¥)
        - level: beginner, intermediate, advanced
    
    Returns:
        - message: ì²˜ë¦¬ ê²°ê³¼ ë©”ì‹œì§€
    """
    # âœ… ë””ë²„ê¹…: ë°›ì€ ë°ì´í„° ì¶œë ¥
    print(f"ğŸ“¥ ë°›ì€ ë°ì´í„°: arxiv_id={request.arxiv_id}, user_id={request.user_id}")
    


    try:

        # 1. user_idë¡œ ì‚¬ìš©ì ì¡°íšŒ ë° level ê°€ì ¸ì˜¤ê¸°
        user = db.query(User).filter(User.user_id == request.user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        level = user.level  # âœ… User í…Œì´ë¸”ì—ì„œ level ê°€ì ¸ì˜¤ê¸°
        print(f"ğŸ‘¤ ì‚¬ìš©ì: user_id={request.user_id}, level={level}")

        # arxiv_id ì •ê·œí™”
        clean_id = request.arxiv_id.replace("arXiv:", "").replace("arxiv:", "").split("v")[0].strip()
        external_id = f"arXiv:{clean_id}"
        
        # DBì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_paper = db.query(Paper).filter(Paper.external_id == external_id).first()
        
        if existing_paper:
            # ì´ë¯¸ í•™ìŠµí•œ ë…¼ë¬¸
            print(f"âš ï¸  ì´ë¯¸ DBì— ì¡´ì¬í•˜ëŠ” ë…¼ë¬¸: paper_id={existing_paper.paper_id}")
            return ArxivAddResponse(message="ì´ë¯¸ í•™ìŠµí•œ ë…¼ë¬¸ì…ë‹ˆë‹¤")
        
        # ìƒˆë¡œìš´ ë…¼ë¬¸ ì²˜ë¦¬
        print(f"ğŸ” ìƒˆë¡œìš´ ë…¼ë¬¸ - arXiv ì¡°íšŒ ì¤‘: {clean_id}")
        
        # 1. arXivì—ì„œ ë…¼ë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        paper_data = fetch_arxiv_paper(clean_id)
        
        # 2. Semantic Scholarì—ì„œ ì¸ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        print(f"ğŸ“Š Semantic Scholar ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì¤‘...")
        ss_metadata = get_semantic_scholar_metadata(paper_data["arxiv_id"])
        paper_data.update(ss_metadata)
        
        # 3. DBì— ì €ì¥
        print(f"ğŸ’¾ DBì— ì €ì¥ ì¤‘...")
        paper_id = save_paper_to_db(paper_data, db)
        paper_data["paper_id"] = paper_id
        paper_data["db_paper_id"] = paper_id
        
        # 4. ìš”ì•½ ìƒì„±
        print(f"âœï¸  ìš”ì•½ ìƒì„± ì¤‘ (level={level})...")  # âœ… ìˆ˜ì •
        description_agent = PaperDescriptionAgent(db=db)
        description_agent.describe(paper_data, level=level)  # âœ… ìˆ˜ì •
        
        # 5. Recommendation í…Œì´ë¸”ì— ì¶”ê°€ (ì‚¬ìš©ìê°€ ì§ì ‘ ìš”ì²­í•œ ë…¼ë¬¸)
        print(f"ğŸ“ Recommendation í…Œì´ë¸”ì— ì¶”ê°€ ì¤‘...")
        recommendation = Recommendation(
            user_id=request.user_id,
            paper_id=paper_id,
            recommended_at=datetime.utcnow(),
            is_user_requested=True,
            requested_paper_id=paper_id
        )
        db.add(recommendation)
        db.commit()
        
        # 6. ì„±ê³µ ë©”ì‹œì§€ ë°˜í™˜
        print(f"âœ… ì™„ë£Œ: paper_id={paper_id}")
        
        return ArxivAddResponse(
            message="ë…¼ë¬¸ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. 'ì§€ê¸ˆê¹Œì§€ ê³µë¶€í•œ ë…¼ë¬¸' í™”ë©´ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”!"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë…¼ë¬¸ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")